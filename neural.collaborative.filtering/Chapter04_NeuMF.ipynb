{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Matrix Factorization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import heapq\n",
    "\n",
    "from time import time\n",
    "from scipy.sparse import load_npz\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils import get_train_instances, get_scores\n",
    "from gmf import GMF, train, evaluate, checkpoint\n",
    "from mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \".\"\n",
    "dataname = \"neuralcf_split.npz\"\n",
    "train_matrix = \"neuralcf_train_sparse.npz\"\n",
    "modeldir = \"models\"\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 512\n",
    "lr = 0.01\n",
    "learner = \"Adam\"\n",
    "lr_scheduler = None\n",
    "\n",
    "n_emb = 8\n",
    "\n",
    "layers = [32, 16, 8]\n",
    "dropouts = [0., 0.]\n",
    "\n",
    "freeze = True\n",
    "\n",
    "# 使用预训练好的GMF和MLP模型, 按照实际的模型名字替代如下字符串\n",
    "mf_pretrain = os.path.join(modeldir, \"GMF_bs_512_lr_001_n_emb_8_lrnr_adam_lrs_wolrs.pt\") #\"GMF_bs_1024_lr_001_n_emb_8_lrnr_adam_lrs_wolrs.pt\")\n",
    "mlp_pretrain = os.path.join(modeldir, \"MLP_bs_512_reg_00_lr_001_n_emb_16_ll_8_dp_wodp_lrnr_adam_lrs_wolrs.pt\")# \"MLP_bs_1024_reg_00_lr_003_n_emb_64_ll_32_dp_wodp_lrnr_adam_lrs_wlrs.pt\")\n",
    "\n",
    "l2reg = 0.\n",
    "\n",
    "validate_every = 1\n",
    "save_model = True\n",
    "n_neg = 4\n",
    "topk = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, n_user, n_item, n_emb, layers, dropouts):\n",
    "        super(NeuMF, self).__init__()\n",
    "\n",
    "        self.layers = layers\n",
    "        self.n_layers = len(layers)\n",
    "        self.dropouts = dropouts\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "\n",
    "        self.mf_embeddings_user = nn.Embedding(n_user, n_emb)\n",
    "        self.mf_embeddings_item = nn.Embedding(n_item, n_emb)\n",
    "\n",
    "        self.mlp_embeddings_user = nn.Embedding(n_user, layers[0]//2)\n",
    "        self.mlp_embeddings_item = nn.Embedding(n_item, layers[0]//2)\n",
    "        self.mlp = nn.Sequential()\n",
    "        for i in range(1,self.n_layers):\n",
    "            self.mlp.add_module(\"linear%d\" %i, nn.Linear(layers[i-1],layers[i]))\n",
    "            self.mlp.add_module(\"relu%d\" %i, torch.nn.ReLU())\n",
    "            self.mlp.add_module(\"dropout%d\" %i , torch.nn.Dropout(p=dropouts[i-1]))\n",
    "\n",
    "        self.out = nn.Linear(in_features=n_emb+layers[-1], out_features=1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Embedding):\n",
    "                nn.init.normal_(m.weight)\n",
    "\n",
    "    def forward(self, users, items):\n",
    "\n",
    "        mf_user_emb = self.mf_embeddings_user(users)\n",
    "        mf_item_emb = self.mf_embeddings_item(items)\n",
    "\n",
    "        mlp_user_emb = self.mlp_embeddings_user(users)\n",
    "        mlp_item_emb = self.mlp_embeddings_item(items)\n",
    "\n",
    "        mf_emb_vector = mf_user_emb*mf_item_emb\n",
    "        mlp_emb_vector = torch.cat([mlp_user_emb,mlp_item_emb], dim=1)\n",
    "        mlp_emb_vector = self.mlp(mlp_emb_vector)\n",
    "\n",
    "        emb_vector = torch.cat([mf_emb_vector,mlp_emb_vector], dim=1)\n",
    "        preds = torch.sigmoid(self.out(emb_vector))\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = NeuMF(n_user=10, n_item=10, n_emb=8, layers=layers, dropouts=dropouts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Load Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = np.load(os.path.join(datadir, dataname))\n",
    "train_ratings = load_npz(os.path.join(datadir, train_matrix)).todok()\n",
    "test_ratings, negatives = dataset['test_negative'], dataset['negatives']\n",
    "n_users, n_items = dataset['n_users'].item(), dataset['n_items'].item()\n",
    "\n",
    "test_loader = DataLoader(dataset=test_ratings,\n",
    "    batch_size=1000,\n",
    "    shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model structures\n",
    "gmf_model = GMF(n_users, n_items, n_emb)\n",
    "gmf_model.load_state_dict(torch.load(mf_pretrain))\n",
    "mlp_model = MLP(n_users, n_items, layers, dropouts)\n",
    "mlp_model.load_state_dict(torch.load(mlp_pretrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GMF(\n",
       "  (embeddings_user): Embedding(123960, 8)\n",
       "  (embeddings_item): Embedding(50052, 8)\n",
       "  (out): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (embeddings_user): Embedding(123960, 16)\n",
       "  (embeddings_item): Embedding(50052, 16)\n",
       "  (mlp): Sequential(\n",
       "    (linear1): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (dropout1): Dropout(p=0.0, inplace=False)\n",
       "    (linear2): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (dropout2): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (out): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuMF(\n",
       "  (mf_embeddings_user): Embedding(123960, 8)\n",
       "  (mf_embeddings_item): Embedding(50052, 8)\n",
       "  (mlp_embeddings_user): Embedding(123960, 16)\n",
       "  (mlp_embeddings_item): Embedding(50052, 16)\n",
       "  (mlp): Sequential(\n",
       "    (linear1): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (dropout1): Dropout(p=0.0, inplace=False)\n",
       "    (linear2): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (dropout2): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuMF(n_users, n_items, n_emb, layers, dropouts)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载模型到 NeuMF model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMF embeddings\n",
    "model.mf_embeddings_item.weight = gmf_model.embeddings_item.weight\n",
    "model.mf_embeddings_user.weight = gmf_model.embeddings_user.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP embeddings\n",
    "model.mlp_embeddings_item.weight = mlp_model.embeddings_item.weight\n",
    "model.mlp_embeddings_user.weight = mlp_model.embeddings_user.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP layers\n",
    "model_dict = model.state_dict()\n",
    "mlp_layers_dict = mlp_model.state_dict()\n",
    "mlp_layers_dict = {k: v for k, v in mlp_layers_dict.items() if 'linear' in k}\n",
    "model_dict.update(mlp_layers_dict)\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction weights\n",
    "mf_prediction_weight, mf_prediction_bias = gmf_model.out.weight, gmf_model.out.bias\n",
    "mlp_prediction_weight, mlp_prediction_bias = mlp_model.out.weight, mlp_model.out.bias\n",
    "\n",
    "new_weight = torch.cat([mf_prediction_weight, mlp_prediction_weight], dim=1)\n",
    "new_bias = mf_prediction_bias + mlp_prediction_bias\n",
    "model.out.weight = torch.nn.Parameter(0.5*new_weight)\n",
    "model.out.bias = torch.nn.Parameter(0.5*new_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Freeze all up to Last (output) Layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "if freeze:\n",
    "    for name, layer in model.named_parameters():\n",
    "        if not (\"out\" in name):\n",
    "            layer.requires_grad = False\n",
    "# or this and pass train_parametes to the optimizer\n",
    "# train_parametes = model.out.parameters() if freeze else model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2reg)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "scheduler = None\n",
    "\n",
    "# let's make sure all is ok\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "trainable_params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(trainable_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All ok, 40 (32+8) weights + a bias is all that we will be training here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 135.22s, LOSS = 0.3660, HR = 0.5330, NDCG = 0.3274, validated in 98.74s\n"
     ]
    }
   ],
   "source": [
    "best_hr, best_ndcgm, best_iter=0,0,0\n",
    "for epoch in range(1,epochs+1):\n",
    "    t1 = time()\n",
    "    loss = train(model, criterion, optimizer, scheduler, epoch, batch_size,\n",
    "        use_cuda, train_ratings, negatives, n_items, n_neg)\n",
    "    t2 = time()\n",
    "    if epoch % validate_every == 0:\n",
    "        (hr, ndcg) = evaluate(model, test_loader, use_cuda, topk)\n",
    "        print(\"Epoch: {} {:.2f}s, LOSS = {:.4f}, HR = {:.4f}, NDCG = {:.4f}, validated in {:.2f}s\".\n",
    "            format(epoch, t2-t1, loss, hr, ndcg, time()-t2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
